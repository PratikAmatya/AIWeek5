{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Algorithm - Classification\n",
    "\n",
    "In this lab, you will learn about how to train and test KNN classifier.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "You will be using Iris-Flower dataset for this lab. The Iris dataset has 4 attributes, i.e., each example in the dataset has four features, in 4-dimensional space:\n",
    "\n",
    " 1. sepal length in cm \n",
    " 2. sepal width in cm \n",
    " 3. petal length in cm \n",
    " 4. petal width in cm \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, the dataset has 3 classes or categories of flowers:\n",
    "\n",
    "1. Iris Setosa \n",
    "2. Iris Versicolour \n",
    "3. Iris Virginica\n",
    "\n",
    "So each example falls into one of the 3 above mentioned classes. The classification task here is no longer a __binary classification problem__ but a __multi-class classification problem__. You can read more about the dataset at: https://archive.ics.uci.edu/ml/datasets/iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports of necessary packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer the following documentations for detail information about `numpy` and `scikit-learn` library:\n",
    "\n",
    "- [numpy](https://numpy.org/)\n",
    "- [scikit-learn](https://scikit-learn.org/stable/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the iris dataset\n",
    "iris_data = load_iris() \n",
    "\n",
    "# extract input features (data)\n",
    "X = iris_data.data\n",
    "\n",
    "# get the label of the dataset\n",
    "y = iris_data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us understand the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many data points are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in X =  150\n",
      "Number of data points in y =  150\n"
     ]
    }
   ],
   "source": [
    "print('Number of data points in X = ', len(X))\n",
    "print('Number of data points in y = ', len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the name of the features (or columns) in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column names in our dataset/list of features\n",
    "iris_data.feature_names "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the labels in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of labels\n",
    "iris_data.target_names "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the first five input data points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the labels of the first five input data points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  [5.1 3.5 1.4 0.2]\n",
      "Label:  0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "What we see as the output below can be interpreted as:\n",
    "\n",
    "sepal length (cm) -> 5.1\n",
    "sepal width (cm) -> 3.5\n",
    "petal length (cm) -> 1.4\n",
    "petal width (cm) -> 0.2\n",
    "\n",
    "label -> 0 i.e. 'setosa' (value at index 0 in the array data.target_names)\n",
    "\"\"\"\n",
    "# print the features of the 1st example/data point from the dataset \n",
    "print(\"Features: \", X[0])\n",
    "# print the label of the 1st example/data point from the dataset\n",
    "print(\"Label: \", y[0])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the dataset into Train, Test & Validation datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train set ($80$ %) and test set ($20$ %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 30\n"
     ]
    }
   ],
   "source": [
    "# number of examples in the train and test set\n",
    "print(len(X_train), len(X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train = \n",
      "[[4.4 3.2 1.3 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.6 2.9 3.6 1.3]]\n",
      "----------------------\n",
      "\n",
      "y_train = \n",
      "[0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train = \")\n",
    "print(X_train[0:5])\n",
    "print('----------------------')\n",
    "print()\n",
    "print(\"y_train = \")\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test = \n",
      "[[5.4 3.4 1.5 0.4]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [5.5 4.2 1.4 0.2]]\n",
      "----------------------\n",
      "\n",
      "y_test = \n",
      "[0 1 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test = \")\n",
    "print(X_test[0:5])\n",
    "print('----------------------')\n",
    "print()\n",
    "print(\"y_test = \")\n",
    "print(y_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the **training** set again into **training** and **validation** set by using the library function, with 20% of the training set examples going inside the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = \\\n",
    "train_test_split(X_train, y_train, test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 24 30\n"
     ]
    }
   ],
   "source": [
    "# number of examples in the train, validation and test set\n",
    "print(len(X_train), len(X_validation), len(X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train = \n",
      "[[5.6 3.  4.5 1.5]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "----------------------\n",
      "\n",
      "y_train = \n",
      "[1 2 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train = \")\n",
    "print(X_train[0:5])\n",
    "print('----------------------')\n",
    "print()\n",
    "print(\"y_train = \")\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_validation = \n",
      "[[6.7 3.1 5.6 2.4]\n",
      " [6.  3.  4.8 1.8]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.8 4.  1.2 0.2]]\n",
      "----------------------\n",
      "\n",
      "y_validation = \n",
      "[2 2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_validation = \")\n",
    "print(X_validation[0:5])\n",
    "print('----------------------')\n",
    "print()\n",
    "print(\"y_validation = \")\n",
    "print(y_validation[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use scikit-learn to build the KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import KNN model \n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN \n",
    "# import function computing accurary of the model\n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train KNN model\n",
    "\n",
    "Assume k = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of neighbors\n",
    "K = 3 \n",
    "# initialize KNN model with K as the number of neighbors\n",
    "model = KNN(n_neighbors=K) \n",
    "# fit the model/train the model\n",
    "model.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the `predictions` for all examples in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the `accuracy` of the model in the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(predictions, y_validation)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Make a prediction on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5. , 3.6, 1.4, 0.2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 5\n",
    "X_validation[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([X_validation[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validation[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do it yourself\n",
    "You can see that using __K = 3__, results in a fairly good accuracy in the validation set, but it may not be the optimal value. What you need to do now is to **find out the best value for K** from a set of values which you must define yourself. Run the above process for each value of K and find out which value of K gives the maximum accuracy on the validation set. \n",
    "\n",
    "Then by using the best value for K, calculate the overall accuracy of the model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute accuracy score for k = 3, 4, 5, 6, 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: 0.9583333333333334, 4: 0.9583333333333334, 5: 0.9583333333333334, 6: 0.9166666666666666, 7: 0.9166666666666666}\n"
     ]
    }
   ],
   "source": [
    "K = {3,4,5,6,7}\n",
    "accuracy = {}\n",
    "for k in K:\n",
    "    # write your code \n",
    "    model = KNN(n_neighbors=k)\n",
    "    model.fit(X_train,y_train)\n",
    "    predictions = model.predict(X_validation)\n",
    "    accuracy[k] = accuracy_score(predictions,y_validation)\n",
    "    \n",
    "# print the accuracy score\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the `best value of k` based on `accuracy score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = max(accuracy.values())\n",
    "best_k = None\n",
    "for key,value in accuracy.items():\n",
    "    if value == max_accuracy:\n",
    "        best_k = key\n",
    "        break\n",
    "\n",
    "print(best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute `accuracy score` on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "final_model = KNN(n_neighbors=best_k)\n",
    "final_model.fit(X_train,y_train)\n",
    "\n",
    "# Write your code\n",
    "pred_test = final_model.predict(X_test)\n",
    "accuracy_test = accuracy_score(pred_test,y_test)\n",
    "\n",
    "# Print accuracy score on test dataset\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are your observations?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
